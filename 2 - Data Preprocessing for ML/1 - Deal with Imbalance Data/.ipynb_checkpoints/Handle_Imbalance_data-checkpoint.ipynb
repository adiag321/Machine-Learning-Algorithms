{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a href = \"https://www.linkedin.com/feed/update/urn:li:activity:6906228386788626432/\">Handling Imbalance Data in Machine learning </a>\n",
    "Get familiar with various techniques to handle the imbalanced class.\n",
    "\n",
    "We have implemented the following imbalance data handeling techniques:\n",
    "\n",
    "1. Random Under-Sampling\n",
    "2. Random Over-Sampling\n",
    "3. Random under-sampling with imblearn\n",
    "4. Random over-sampling with imblearn\n",
    "5. Under-sampling: Tomek links\n",
    "6. Synthetic Minority Oversampling Technique (SMOTE)\n",
    "7. NearMiss\n",
    "8. Change the performance metric\n",
    "9. Penalize Algorithms (Cost-Sensitive Training)\n",
    "10. Change the algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.datasets import load_boston \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>541</td>\n",
       "      <td>406.0</td>\n",
       "      <td>-2.312227</td>\n",
       "      <td>1.951992</td>\n",
       "      <td>-1.609851</td>\n",
       "      <td>3.997906</td>\n",
       "      <td>-0.522188</td>\n",
       "      <td>-1.426545</td>\n",
       "      <td>-2.537387</td>\n",
       "      <td>1.391657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517232</td>\n",
       "      <td>-0.035049</td>\n",
       "      <td>-0.465211</td>\n",
       "      <td>0.320198</td>\n",
       "      <td>0.044519</td>\n",
       "      <td>0.177840</td>\n",
       "      <td>0.261145</td>\n",
       "      <td>-0.143276</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>623</td>\n",
       "      <td>472.0</td>\n",
       "      <td>-3.043541</td>\n",
       "      <td>-3.157307</td>\n",
       "      <td>1.088463</td>\n",
       "      <td>2.288644</td>\n",
       "      <td>1.359805</td>\n",
       "      <td>-1.064823</td>\n",
       "      <td>0.325574</td>\n",
       "      <td>-0.067794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661696</td>\n",
       "      <td>0.435477</td>\n",
       "      <td>1.375966</td>\n",
       "      <td>-0.293803</td>\n",
       "      <td>0.279798</td>\n",
       "      <td>-0.145362</td>\n",
       "      <td>-0.252773</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>529.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4920</td>\n",
       "      <td>4462.0</td>\n",
       "      <td>-2.303350</td>\n",
       "      <td>1.759247</td>\n",
       "      <td>-0.359745</td>\n",
       "      <td>2.330243</td>\n",
       "      <td>-0.821628</td>\n",
       "      <td>-0.075788</td>\n",
       "      <td>0.562320</td>\n",
       "      <td>-0.399147</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.294166</td>\n",
       "      <td>-0.932391</td>\n",
       "      <td>0.172726</td>\n",
       "      <td>-0.087330</td>\n",
       "      <td>-0.156114</td>\n",
       "      <td>-0.542628</td>\n",
       "      <td>0.039566</td>\n",
       "      <td>-0.153029</td>\n",
       "      <td>239.93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6108</td>\n",
       "      <td>6986.0</td>\n",
       "      <td>-4.397974</td>\n",
       "      <td>1.358367</td>\n",
       "      <td>-2.592844</td>\n",
       "      <td>2.679787</td>\n",
       "      <td>-1.128131</td>\n",
       "      <td>-1.706536</td>\n",
       "      <td>-3.496197</td>\n",
       "      <td>-0.248778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573574</td>\n",
       "      <td>0.176968</td>\n",
       "      <td>-0.436207</td>\n",
       "      <td>-0.053502</td>\n",
       "      <td>0.252405</td>\n",
       "      <td>-0.657488</td>\n",
       "      <td>-0.827136</td>\n",
       "      <td>0.849573</td>\n",
       "      <td>59.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6329</td>\n",
       "      <td>7519.0</td>\n",
       "      <td>1.234235</td>\n",
       "      <td>3.019740</td>\n",
       "      <td>-4.304597</td>\n",
       "      <td>4.732795</td>\n",
       "      <td>3.624201</td>\n",
       "      <td>-1.357746</td>\n",
       "      <td>1.713445</td>\n",
       "      <td>-0.496358</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.379068</td>\n",
       "      <td>-0.704181</td>\n",
       "      <td>-0.656805</td>\n",
       "      <td>-1.632653</td>\n",
       "      <td>1.488901</td>\n",
       "      <td>0.566797</td>\n",
       "      <td>-0.010016</td>\n",
       "      <td>0.146793</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    Time        V1        V2        V3        V4        V5  \\\n",
       "0         541   406.0 -2.312227  1.951992 -1.609851  3.997906 -0.522188   \n",
       "1         623   472.0 -3.043541 -3.157307  1.088463  2.288644  1.359805   \n",
       "2        4920  4462.0 -2.303350  1.759247 -0.359745  2.330243 -0.821628   \n",
       "3        6108  6986.0 -4.397974  1.358367 -2.592844  2.679787 -1.128131   \n",
       "4        6329  7519.0  1.234235  3.019740 -4.304597  4.732795  3.624201   \n",
       "\n",
       "         V6        V7        V8  ...       V21       V22       V23       V24  \\\n",
       "0 -1.426545 -2.537387  1.391657  ...  0.517232 -0.035049 -0.465211  0.320198   \n",
       "1 -1.064823  0.325574 -0.067794  ...  0.661696  0.435477  1.375966 -0.293803   \n",
       "2 -0.075788  0.562320 -0.399147  ... -0.294166 -0.932391  0.172726 -0.087330   \n",
       "3 -1.706536 -3.496197 -0.248778  ...  0.573574  0.176968 -0.436207 -0.053502   \n",
       "4 -1.357746  1.713445 -0.496358  ... -0.379068 -0.704181 -0.656805 -1.632653   \n",
       "\n",
       "        V25       V26       V27       V28  Amount  Class  \n",
       "0  0.044519  0.177840  0.261145 -0.143276    0.00      1  \n",
       "1  0.279798 -0.145362 -0.252773  0.035764  529.00      1  \n",
       "2 -0.156114 -0.542628  0.039566 -0.153029  239.93      1  \n",
       "3  0.252405 -0.657488 -0.827136  0.849573   59.00      1  \n",
       "4  1.488901  0.566797 -0.010016  0.146793    1.00      1  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"/Users/adityaagarwal/Aditya Ag/Jupyter Notebook/Deal with Imbalance Data/credit-card.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9492, 32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9000\n",
       "1     492\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Class.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking the orginal data into account and predicting the Fraud and Non-Fraud Cases - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>236031</td>\n",
       "      <td>148645.0</td>\n",
       "      <td>2.087131</td>\n",
       "      <td>0.174699</td>\n",
       "      <td>-1.762514</td>\n",
       "      <td>0.378010</td>\n",
       "      <td>0.515231</td>\n",
       "      <td>-0.785758</td>\n",
       "      <td>0.199287</td>\n",
       "      <td>-0.241249</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.372191</td>\n",
       "      <td>-0.951858</td>\n",
       "      <td>0.317775</td>\n",
       "      <td>0.386025</td>\n",
       "      <td>-0.228262</td>\n",
       "      <td>0.180525</td>\n",
       "      <td>-0.061110</td>\n",
       "      <td>-0.031560</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>271257</td>\n",
       "      <td>164489.0</td>\n",
       "      <td>0.039062</td>\n",
       "      <td>0.889239</td>\n",
       "      <td>0.302199</td>\n",
       "      <td>-0.585161</td>\n",
       "      <td>0.431838</td>\n",
       "      <td>-1.116524</td>\n",
       "      <td>1.050711</td>\n",
       "      <td>-0.232965</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.253421</td>\n",
       "      <td>-0.535450</td>\n",
       "      <td>0.072419</td>\n",
       "      <td>0.050588</td>\n",
       "      <td>-0.475029</td>\n",
       "      <td>0.136236</td>\n",
       "      <td>0.248946</td>\n",
       "      <td>0.098623</td>\n",
       "      <td>5.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>218413</td>\n",
       "      <td>141305.0</td>\n",
       "      <td>-0.334332</td>\n",
       "      <td>-0.279289</td>\n",
       "      <td>0.558407</td>\n",
       "      <td>-2.721258</td>\n",
       "      <td>0.222245</td>\n",
       "      <td>0.105259</td>\n",
       "      <td>0.424721</td>\n",
       "      <td>-0.808027</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.332232</td>\n",
       "      <td>0.203322</td>\n",
       "      <td>-0.152383</td>\n",
       "      <td>0.015132</td>\n",
       "      <td>-0.389804</td>\n",
       "      <td>-0.234411</td>\n",
       "      <td>-0.325232</td>\n",
       "      <td>-0.354962</td>\n",
       "      <td>20.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>128653</td>\n",
       "      <td>78791.0</td>\n",
       "      <td>1.145310</td>\n",
       "      <td>0.038190</td>\n",
       "      <td>1.103411</td>\n",
       "      <td>1.676224</td>\n",
       "      <td>-0.881220</td>\n",
       "      <td>-0.371989</td>\n",
       "      <td>-0.297177</td>\n",
       "      <td>0.009028</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.092300</td>\n",
       "      <td>0.083340</td>\n",
       "      <td>-0.058040</td>\n",
       "      <td>0.749869</td>\n",
       "      <td>0.647730</td>\n",
       "      <td>-0.308037</td>\n",
       "      <td>0.058254</td>\n",
       "      <td>0.029025</td>\n",
       "      <td>5.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>153965</td>\n",
       "      <td>100832.0</td>\n",
       "      <td>1.890476</td>\n",
       "      <td>-0.561657</td>\n",
       "      <td>0.129218</td>\n",
       "      <td>0.394991</td>\n",
       "      <td>-0.803205</td>\n",
       "      <td>0.139739</td>\n",
       "      <td>-1.054481</td>\n",
       "      <td>0.121556</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.061418</td>\n",
       "      <td>0.139415</td>\n",
       "      <td>0.258049</td>\n",
       "      <td>-0.424712</td>\n",
       "      <td>-0.630249</td>\n",
       "      <td>0.445302</td>\n",
       "      <td>-0.044791</td>\n",
       "      <td>-0.052782</td>\n",
       "      <td>39.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9487</th>\n",
       "      <td>207634</td>\n",
       "      <td>136765.0</td>\n",
       "      <td>-5.493186</td>\n",
       "      <td>4.057918</td>\n",
       "      <td>-1.795148</td>\n",
       "      <td>-0.522112</td>\n",
       "      <td>-3.901231</td>\n",
       "      <td>-0.338767</td>\n",
       "      <td>-4.216907</td>\n",
       "      <td>1.655481</td>\n",
       "      <td>...</td>\n",
       "      <td>2.827709</td>\n",
       "      <td>-0.480805</td>\n",
       "      <td>0.883135</td>\n",
       "      <td>0.476372</td>\n",
       "      <td>-0.422392</td>\n",
       "      <td>0.266097</td>\n",
       "      <td>-1.249686</td>\n",
       "      <td>-0.237272</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9488</th>\n",
       "      <td>210369</td>\n",
       "      <td>137949.0</td>\n",
       "      <td>1.939843</td>\n",
       "      <td>-0.434933</td>\n",
       "      <td>-0.345178</td>\n",
       "      <td>0.307799</td>\n",
       "      <td>-0.487803</td>\n",
       "      <td>0.113880</td>\n",
       "      <td>-0.729222</td>\n",
       "      <td>0.152521</td>\n",
       "      <td>...</td>\n",
       "      <td>0.246981</td>\n",
       "      <td>0.914658</td>\n",
       "      <td>0.141960</td>\n",
       "      <td>0.799542</td>\n",
       "      <td>-0.099047</td>\n",
       "      <td>-0.270436</td>\n",
       "      <td>0.035708</td>\n",
       "      <td>-0.038128</td>\n",
       "      <td>9.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9489</th>\n",
       "      <td>211880</td>\n",
       "      <td>138612.0</td>\n",
       "      <td>1.798427</td>\n",
       "      <td>-0.160432</td>\n",
       "      <td>-1.920048</td>\n",
       "      <td>1.051255</td>\n",
       "      <td>1.204895</td>\n",
       "      <td>0.892956</td>\n",
       "      <td>0.324847</td>\n",
       "      <td>0.194731</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176878</td>\n",
       "      <td>0.684760</td>\n",
       "      <td>-0.019825</td>\n",
       "      <td>-1.506229</td>\n",
       "      <td>0.238479</td>\n",
       "      <td>-0.389693</td>\n",
       "      <td>0.019441</td>\n",
       "      <td>-0.080415</td>\n",
       "      <td>55.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9490</th>\n",
       "      <td>273066</td>\n",
       "      <td>165405.0</td>\n",
       "      <td>2.114637</td>\n",
       "      <td>-0.211168</td>\n",
       "      <td>-1.638108</td>\n",
       "      <td>-0.010894</td>\n",
       "      <td>0.490466</td>\n",
       "      <td>-0.130107</td>\n",
       "      <td>-0.015770</td>\n",
       "      <td>-0.042934</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.339011</td>\n",
       "      <td>-0.921378</td>\n",
       "      <td>0.170633</td>\n",
       "      <td>-1.413620</td>\n",
       "      <td>-0.180180</td>\n",
       "      <td>0.266670</td>\n",
       "      <td>-0.082983</td>\n",
       "      <td>-0.086125</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9491</th>\n",
       "      <td>126327</td>\n",
       "      <td>77984.0</td>\n",
       "      <td>-0.298551</td>\n",
       "      <td>1.100801</td>\n",
       "      <td>0.841074</td>\n",
       "      <td>-0.335169</td>\n",
       "      <td>0.714700</td>\n",
       "      <td>0.023175</td>\n",
       "      <td>0.624201</td>\n",
       "      <td>0.112563</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.282316</td>\n",
       "      <td>-0.739245</td>\n",
       "      <td>-0.182471</td>\n",
       "      <td>-0.871434</td>\n",
       "      <td>-0.013802</td>\n",
       "      <td>0.124734</td>\n",
       "      <td>0.244955</td>\n",
       "      <td>0.077531</td>\n",
       "      <td>1.98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9000 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0      Time        V1        V2        V3        V4        V5  \\\n",
       "492       236031  148645.0  2.087131  0.174699 -1.762514  0.378010  0.515231   \n",
       "493       271257  164489.0  0.039062  0.889239  0.302199 -0.585161  0.431838   \n",
       "494       218413  141305.0 -0.334332 -0.279289  0.558407 -2.721258  0.222245   \n",
       "495       128653   78791.0  1.145310  0.038190  1.103411  1.676224 -0.881220   \n",
       "496       153965  100832.0  1.890476 -0.561657  0.129218  0.394991 -0.803205   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "9487      207634  136765.0 -5.493186  4.057918 -1.795148 -0.522112 -3.901231   \n",
       "9488      210369  137949.0  1.939843 -0.434933 -0.345178  0.307799 -0.487803   \n",
       "9489      211880  138612.0  1.798427 -0.160432 -1.920048  1.051255  1.204895   \n",
       "9490      273066  165405.0  2.114637 -0.211168 -1.638108 -0.010894  0.490466   \n",
       "9491      126327   77984.0 -0.298551  1.100801  0.841074 -0.335169  0.714700   \n",
       "\n",
       "            V6        V7        V8  ...       V21       V22       V23  \\\n",
       "492  -0.785758  0.199287 -0.241249  ... -0.372191 -0.951858  0.317775   \n",
       "493  -1.116524  1.050711 -0.232965  ... -0.253421 -0.535450  0.072419   \n",
       "494   0.105259  0.424721 -0.808027  ... -0.332232  0.203322 -0.152383   \n",
       "495  -0.371989 -0.297177  0.009028  ... -0.092300  0.083340 -0.058040   \n",
       "496   0.139739 -1.054481  0.121556  ... -0.061418  0.139415  0.258049   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "9487 -0.338767 -4.216907  1.655481  ...  2.827709 -0.480805  0.883135   \n",
       "9488  0.113880 -0.729222  0.152521  ...  0.246981  0.914658  0.141960   \n",
       "9489  0.892956  0.324847  0.194731  ...  0.176878  0.684760 -0.019825   \n",
       "9490 -0.130107 -0.015770 -0.042934  ... -0.339011 -0.921378  0.170633   \n",
       "9491  0.023175  0.624201  0.112563  ... -0.282316 -0.739245 -0.182471   \n",
       "\n",
       "           V24       V25       V26       V27       V28  Amount  Class  \n",
       "492   0.386025 -0.228262  0.180525 -0.061110 -0.031560    1.29      0  \n",
       "493   0.050588 -0.475029  0.136236  0.248946  0.098623    5.99      0  \n",
       "494   0.015132 -0.389804 -0.234411 -0.325232 -0.354962   20.00      0  \n",
       "495   0.749869  0.647730 -0.308037  0.058254  0.029025    5.00      0  \n",
       "496  -0.424712 -0.630249  0.445302 -0.044791 -0.052782   39.00      0  \n",
       "...        ...       ...       ...       ...       ...     ...    ...  \n",
       "9487  0.476372 -0.422392  0.266097 -1.249686 -0.237272    0.74      0  \n",
       "9488  0.799542 -0.099047 -0.270436  0.035708 -0.038128    9.99      0  \n",
       "9489 -1.506229  0.238479 -0.389693  0.019441 -0.080415   55.00      0  \n",
       "9490 -1.413620 -0.180180  0.266670 -0.082983 -0.086125    1.98      0  \n",
       "9491 -0.871434 -0.013802  0.124734  0.244955  0.077531    1.98      0  \n",
       "\n",
       "[9000 rows x 32 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_0 = data[data['Class']==0]\n",
    "data_1 = data[data['Class']==1]\n",
    "data_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fraudulent Cases - (1): 492\n",
      "Not Fraudulent Cases - (0): 9000\n",
      "\n",
      " Percent of Fraudulent Cases is  5.466666666666667\n"
     ]
    }
   ],
   "source": [
    "# Checking the number of Fraudulent and Non-Fraudulent Cases\n",
    "\n",
    "count = data['Class'].value_counts()\n",
    "\n",
    "print('Fraudulent Cases - (1):', count[1])\n",
    "print('Not Fraudulent Cases - (0):', count[0])\n",
    "\n",
    "# print the percentage of question where target == 1\n",
    "print(\"\\n Percent of Fraudulent Cases is \", count[1]/count[0]* 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(0, 0, 'Non Fraud'), Text(1, 0, 'Fraud')]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data['Class']).set_xticklabels(['Non Fraud', 'Fraud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "Time          0\n",
       "V1            0\n",
       "V2            0\n",
       "V3            0\n",
       "V4            0\n",
       "V5            0\n",
       "V6            0\n",
       "V7            0\n",
       "V8            0\n",
       "V9            0\n",
       "V10           0\n",
       "V11           0\n",
       "V12           0\n",
       "V13           0\n",
       "V14           0\n",
       "V15           0\n",
       "V16           0\n",
       "V17           0\n",
       "V18           0\n",
       "V19           0\n",
       "V20           0\n",
       "V21           0\n",
       "V22           0\n",
       "V23           0\n",
       "V24           0\n",
       "V25           0\n",
       "V26           0\n",
       "V27           0\n",
       "V28           0\n",
       "Amount        0\n",
       "Class         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for Null values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting the dataset into Predictor (X) and Response (Y) Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.iloc[:,:-1]\n",
    "y = data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7593, 31) (1899, 31) (7593,) (1899,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "# Fitting the model\n",
    "model.fit(x, y)\n",
    "# Prediction\n",
    "y_predict = model.predict(x)\n",
    "y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is  98.81 %\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy score is \",round(accuracy_score(y_predict, y)*100,2),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7593\n",
      "1899\n",
      "9492\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape[0])\n",
    "print(y_test.shape[0])\n",
    "\n",
    "if (y_train.shape[0] + y_test.shape[0] == y.shape[0]):\n",
    "    print(y.shape[0])\n",
    "else:\n",
    "    print(\"Train_test Split did not occur properly\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8965,   78],\n",
       "       [  35,  414]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_predict, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating a Function for Logistic Regression - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_reg(data):\n",
    "    x = data.iloc[:,:-1]\n",
    "    y = data.iloc[:,-1]\n",
    "    print(\"Shape of X\",x.shape)\n",
    "    print(\"Shape of Y\",y.shape)\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "    \n",
    "    model = LogisticRegression()\n",
    "    # Fitting the model\n",
    "    model.fit(x, y)\n",
    "    # Prediction\n",
    "    y_predict = model.predict(x)\n",
    "    accuracy = round(accuracy_score(y_predict, y)*100,2)\n",
    "    return print(\"Accuracy of the model is \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Resampling Techniques\n",
    "\n",
    "A widely adopted technique for dealing with highly unbalanced datasets is called resampling. It consists of removing samples from the majority class (under-sampling) and/or adding more examples from the minority class (over-sampling). <br>\n",
    "\n",
    "The simplest implementation of over-sampling is to duplicate random records from the minority class, which can cause overfishing. <br>\n",
    "\n",
    "In under-sampling, the simplest technique involves removing random records from the majority class, which can cause loss of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000\n",
      "492\n"
     ]
    }
   ],
   "source": [
    "# class count\n",
    "class_count_0, class_count_1 = data['Class'].value_counts()\n",
    "print(class_count_0)\n",
    "print(class_count_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class 0: (9000, 32)\n",
      "\n",
      "class 1: (492, 32)\n"
     ]
    }
   ],
   "source": [
    "# divide class group into 1 and 0\n",
    "class_0 = data[data['Class'] == 0]\n",
    "class_1 = data[data['Class'] == 1]\n",
    "\n",
    "# print the shape of the class\n",
    "print('class 0:', class_0.shape)\n",
    "print('\\nclass 1:', class_1.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Random under sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 1s = 492 (minority) and 0s = 9000 (majority)\n",
    "In Random undersampling method, we randomly take 492 (Minority class) samples from our Majority class <br>\n",
    "\n",
    "Undersampling can be defined as removing some observations of the majority class. This is done until the majority and minority class is balanced out. <br>\n",
    "\n",
    "Undersampling can be a good choice when you have a ton of data -think millions of rows. But a drawback to undersampling is that we are removing information that may be valuable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total class of 1 and 0:\n",
      " 0    492\n",
      "1    492\n",
      "Name: Class, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Count the target values'}>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Randomly taking 492 samples from class_0\n",
    "class_0_under_sample = class_0.sample(class_count_1)\n",
    "# concat \n",
    "test_under = pd.concat([class_0_under_sample, class_1], axis=0)\n",
    "\n",
    "print(\"total class of 1 and 0:\\n\",test_under['Class'].value_counts())\n",
    "\n",
    "test_under['Class'].value_counts().plot(kind='bar', title='Count the target values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X (984, 31)\n",
      "Shape of Y (984,)\n",
      "Accuracy of the model is  94.0\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Accuracy for Undersampled Dataset\n",
    "log_reg(test_under)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Random over sampling \n",
    "\n",
    "Oversampling can be defined as adding more copies to the minority class. Oversampling can be a good choice when you don’t have a ton of data to work with.\n",
    "\n",
    "A con to consider when undersampling is that it can cause overfitting and poor generalization to your test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class count of 1 and 0:\n",
      " 0    9000\n",
      "1    9000\n",
      "Name: Class, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Count (target)'}>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEFCAYAAAAPCDf9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAQqUlEQVR4nO3dfZCdZXnH8e+vifIiIiALYoIGa3wBOmqJCPVlOkOnRK0NfxQbX6NjJzMMtFqtFdRR6piO7bSOMgozjC+EQkWKVFIVLaZlrCMVF98oRCQjhaREWBEUtYLA1T/ODR43m92zNpxdcn8/M2fOc67nvp9znWTz22fv85xNqgpJUh9+Y6EbkCSNj6EvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+apyQTSW5IsvdC9zKTJHsl+U6SQxa6Fy0+hr4WpSSvTDKZ5CdJdiS5PMkLxvC8leSpcww7Hfh4Vf28zbkyyZ883L3tyvTnr6p7gI8Bb1uonrR4GfpadJK8GfgA8NfAocCTgLOBNQvYFjA4iwbWARfsxmMu3V3HGvKPwLrWr/QQQ1+LSpLHAe8BTq2qS6vqp1X1i6r6l6p6axuzV5IPJLm13T7wYLgleV2SL0875kNn70nOS/LhJJ9NcneSryb5zbbvS23Kt9pPGH88Q4vPA+6qqu1tzgbghcCH2pwPtfoHk2xL8uMk1yR54VA/Zya5JMkFSX4MvC7JEUm+1Hr6YuvxgqE5xyX5SpK7knwrye/O9vytvzuB4379vw3tiQx9LTbHA3sD/zzLmHcwCLNnA88CjgXeOY/neAXwV8CBwFZgA0BVvajtf1ZV7VdVn5xh7m8BNzz4oKreAfwHcFqbc1rb9bXW30EMzrr/adp7AGuAS4ADgAvbmKuBxwNnAq95cGCSZcBngfe24/0F8KkkE7M8P8AWBn8+0kMMfS02jwd+UFX3zTLmVcB7qur2qppiEOCvmWX8dJdW1dXtOS5kEM6jOgC4e65BVXVBVd1RVfdV1d8DewFPHxpyVVV9uqoeACaA5wLvqqp7q+rLwKahsa8GPldVn6uqB6rqCmASeMkcbdzd+pUeYuhrsbkDOHiOde4nAjcPPb651Ub1/aHtnwH7zWPuncBj5xqU5C1JtiT5UZK7gMcBBw8N2Ta0/UTgh1X1s13sfzJwclvauasd7wXAYXO08Vjgrrl6VV8MfS02VwE/B06aZcytDILwQU9qNYCfAvs+uCPJE3Zzf98Gnjat9iu/qrat378NeDlwYFUdAPwIyC7m7AAOSrLvUO3woe1twD9U1QFDt8dU1ftmev4hzwS+NcJrUkcMfS0qVfUj4F3Ah5OclGTfJI9K8uIkf9uGfQJ4Z7te/uA2/sE3Pb8FHJXk2W0N/cx5tnAb8JRZ9l8NHNDW2Xc157HAfcAUsDTJu4D9d3XAqrqZwXLNmUkeneR44GVDQy4AXpbkxCRLkuyd5HeTLN9Vz62/g4D/nOW1qEOGvhadqno/8GYGb85OMTjTPQ34dBvyXgYh+W3gWuDrrUZVfZfB1T9fBG4EfuVKnhGcCWxsyygvn6G3e4HzGKyzP+iDwB8luTPJWcAXgMuB7zJYevo5v7pcM5NXMXgT+472Wj4J3NOecxuDN37fzi//PN7KL//9Tn9+gFcCG9s1+9JD4n+iIs1PkgkGV8w8p6r+92F6jk8C36mqd/8ac/di8BPPi6rq9t3enB7RDH1pEUjyXOCHwE3A7zP4qeb4qvrGQvalPc/D8UlASfP3BOBSBpesbgdOMfD1cPBMX5I64hu5ktQRQ1+SOrLo1/QPPvjgWrFixUK3IUmPKNdcc80Pqmpien3Rh/6KFSuYnJxc6DYk6RElyc0z1V3ekaSOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHVk0X8465FixemfXegW9hj//b6XLnQLexS/NnevR/rXp2f6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkdGCv0kf57kuiT/leQTSfZOclCSK5Lc2O4PHBp/RpKtSW5IcuJQ/Zgk17Z9ZyXJw/GiJEkzmzP0kywD/gxYVVVHA0uAtcDpwOaqWglsbo9JcmTbfxSwGjg7yZJ2uHOA9cDKdlu9W1+NJGlWoy7vLAX2SbIU2Be4FVgDbGz7NwInte01wEVVdU9V3QRsBY5Nchiwf1VdVVUFnD80R5I0BnOGflX9D/B3wC3ADuBHVfWvwKFVtaON2QEc0qYsA7YNHWJ7qy1r29PrO0myPslkksmpqan5vSJJ0i6NsrxzIIOz9yOAJwKPSfLq2abMUKtZ6jsXq86tqlVVtWpiYmKuFiVJIxpleef3gJuqaqqqfgFcCvwOcFtbsqHd397GbwcOH5q/nMFy0Pa2Pb0uSRqTUUL/FuC4JPu2q21OALYAm4B1bcw64LK2vQlYm2SvJEcweMP26rYEdHeS49pxXjs0R5I0BkvnGlBVX01yCfB14D7gG8C5wH7AxUnewOAbw8lt/HVJLgaub+NPrar72+FOAc4D9gEubzdJ0pjMGfoAVfVu4N3TyvcwOOufafwGYMMM9Ung6Hn2KEnaTfxEriR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkdGCv0kByS5JMl3kmxJcnySg5JckeTGdn/g0PgzkmxNckOSE4fqxyS5tu07K0kejhclSZrZqGf6HwQ+X1XPAJ4FbAFOBzZX1Upgc3tMkiOBtcBRwGrg7CRL2nHOAdYDK9tt9W56HZKkEcwZ+kn2B14EfBSgqu6tqruANcDGNmwjcFLbXgNcVFX3VNVNwFbg2CSHAftX1VVVVcD5Q3MkSWMwypn+U4Ap4ONJvpHkI0keAxxaVTsA2v0hbfwyYNvQ/O2ttqxtT6/vJMn6JJNJJqempub1giRJuzZK6C8Ffhs4p6qeA/yUtpSzCzOt09cs9Z2LVedW1aqqWjUxMTFCi5KkUYwS+tuB7VX11fb4EgbfBG5rSza0+9uHxh8+NH85cGurL5+hLkkakzlDv6q+D2xL8vRWOgG4HtgErGu1dcBlbXsTsDbJXkmOYPCG7dVtCejuJMe1q3ZeOzRHkjQGS0cc96fAhUkeDXwPeD2DbxgXJ3kDcAtwMkBVXZfkYgbfGO4DTq2q+9txTgHOA/YBLm83SdKYjBT6VfVNYNUMu07YxfgNwIYZ6pPA0fPoT5K0G/mJXEnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI6MHPpJliT5RpLPtMcHJbkiyY3t/sChsWck2ZrkhiQnDtWPSXJt23dWkuzelyNJms18zvTfCGwZenw6sLmqVgKb22OSHAmsBY4CVgNnJ1nS5pwDrAdWttvq/1f3kqR5GSn0kywHXgp8ZKi8BtjYtjcCJw3VL6qqe6rqJmArcGySw4D9q+qqqirg/KE5kqQxGPVM/wPAXwIPDNUOraodAO3+kFZfBmwbGre91Za17en1nSRZn2QyyeTU1NSILUqS5jJn6Cf5A+D2qrpmxGPOtE5fs9R3LladW1WrqmrVxMTEiE8rSZrL0hHGPB/4wyQvAfYG9k9yAXBbksOqakdburm9jd8OHD40fzlwa6svn6EuSRqTOc/0q+qMqlpeVSsYvEH7b1X1amATsK4NWwdc1rY3AWuT7JXkCAZv2F7dloDuTnJcu2rntUNzJEljMMqZ/q68D7g4yRuAW4CTAarquiQXA9cD9wGnVtX9bc4pwHnAPsDl7SZJGpN5hX5VXQlc2bbvAE7YxbgNwIYZ6pPA0fNtUpK0e/iJXEnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI7MGfpJDk/y70m2JLkuyRtb/aAkVyS5sd0fODTnjCRbk9yQ5MSh+jFJrm37zkqSh+dlSZJmMsqZ/n3AW6rqmcBxwKlJjgROBzZX1Upgc3tM27cWOApYDZydZEk71jnAemBlu63eja9FkjSHOUO/qnZU1dfb9t3AFmAZsAbY2IZtBE5q22uAi6rqnqq6CdgKHJvkMGD/qrqqqgo4f2iOJGkM5rWmn2QF8Bzgq8ChVbUDBt8YgEPasGXAtqFp21ttWdueXp/pedYnmUwyOTU1NZ8WJUmzGDn0k+wHfAp4U1X9eLahM9RqlvrOxapzq2pVVa2amJgYtUVJ0hxGCv0kj2IQ+BdW1aWtfFtbsqHd397q24HDh6YvB25t9eUz1CVJYzLK1TsBPgpsqar3D+3aBKxr2+uAy4bqa5PsleQIBm/YXt2WgO5Oclw75muH5kiSxmDpCGOeD7wGuDbJN1vt7cD7gIuTvAG4BTgZoKquS3IxcD2DK39Orar727xTgPOAfYDL202SNCZzhn5VfZmZ1+MBTtjFnA3Ahhnqk8DR82lQkrT7+IlcSeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjow99JOsTnJDkq1JTh/380tSz8Ya+kmWAB8GXgwcCbwiyZHj7EGSejbuM/1jga1V9b2quhe4CFgz5h4kqVtLx/x8y4BtQ4+3A8+bPijJemB9e/iTJDeMobceHAz8YKGbmEv+ZqE70ALx63P3evJMxXGHfmao1U6FqnOBcx/+dvqSZLKqVi10H9JM/Pocj3Ev72wHDh96vBy4dcw9SFK3xh36XwNWJjkiyaOBtcCmMfcgSd0a6/JOVd2X5DTgC8AS4GNVdd04e+icS2ZazPz6HINU7bSkLknaQ/mJXEnqiKEvSR0x9CWpI+O+Tl9jlOQZDD7xvIzB5yFuBTZV1ZYFbUzSgvFMfw+V5G0Mfs1FgKsZXC4b4BP+ojstZklev9A97Mm8emcPleS7wFFV9Ytp9UcD11XVyoXpTJpdkluq6kkL3ceeyuWdPdcDwBOBm6fVD2v7pAWT5Nu72gUcOs5eemPo77neBGxOciO//CV3TwKeCpy2UE1JzaHAicCd0+oBvjL+dvph6O+hqurzSZ7G4NdZL2Pwj2k78LWqun9Bm5PgM8B+VfXN6TuSXDn2bjrimr4kdcSrdySpI4a+JHXE0Jekjhj6ktQRQ1+SOvJ/zhtN3wAJWsoAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_1_over = class_1.sample(class_count_0, replace=True)\n",
    "\n",
    "test_over = pd.concat([class_1_over, class_0], axis=0)\n",
    "\n",
    "# print the number of class count\n",
    "print('class count of 1 and 0:\\n', test_over['Class'].value_counts())\n",
    "\n",
    "# plot the count\n",
    "test_over['Class'].value_counts().plot(kind='bar', title='Count (target)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X (18000, 31)\n",
      "Shape of Y (18000,)\n",
      "Accuracy of the model is  91.46\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Accuracy for Undersampled Dataset\n",
    "log_reg(test_over)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Random under-sampling with imblearn\n",
    "RandomUnderSampler is a fast and easy way to balance the data by randomly selecting a subset of data for the targeted classes. <br>\n",
    "\n",
    "Under-sample the majority class(es) by randomly picking samples with or without replacement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original dataset shape: Counter({0: 9000, 1: 492})\n",
      "Resample dataset shape Counter({0: 492, 1: 492})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=42, replacement=True) \n",
    "\n",
    "# fit predictor and target variable\n",
    "x_rus, y_rus = rus.fit_resample(x, y)\n",
    "print('original dataset shape:', Counter(y))\n",
    "print('Resample dataset shape', Counter(y_rus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>195843</td>\n",
       "      <td>131245.0</td>\n",
       "      <td>2.113416</td>\n",
       "      <td>-1.778946</td>\n",
       "      <td>-0.270242</td>\n",
       "      <td>-1.435794</td>\n",
       "      <td>-1.934593</td>\n",
       "      <td>-0.404340</td>\n",
       "      <td>-1.605464</td>\n",
       "      <td>0.028426</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130515</td>\n",
       "      <td>0.816912</td>\n",
       "      <td>0.124606</td>\n",
       "      <td>0.080239</td>\n",
       "      <td>-0.286359</td>\n",
       "      <td>-0.017499</td>\n",
       "      <td>0.030221</td>\n",
       "      <td>-0.043715</td>\n",
       "      <td>63.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>175540</td>\n",
       "      <td>122383.0</td>\n",
       "      <td>1.807996</td>\n",
       "      <td>0.175712</td>\n",
       "      <td>0.078832</td>\n",
       "      <td>4.087285</td>\n",
       "      <td>-0.395966</td>\n",
       "      <td>0.137835</td>\n",
       "      <td>-0.377114</td>\n",
       "      <td>0.219787</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152284</td>\n",
       "      <td>0.614129</td>\n",
       "      <td>0.158536</td>\n",
       "      <td>0.510383</td>\n",
       "      <td>-0.057457</td>\n",
       "      <td>0.085855</td>\n",
       "      <td>-0.016525</td>\n",
       "      <td>-0.055248</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49890</td>\n",
       "      <td>44253.0</td>\n",
       "      <td>1.235299</td>\n",
       "      <td>0.406386</td>\n",
       "      <td>0.455123</td>\n",
       "      <td>0.763918</td>\n",
       "      <td>-0.479694</td>\n",
       "      <td>-1.246685</td>\n",
       "      <td>0.130762</td>\n",
       "      <td>-0.256403</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.260211</td>\n",
       "      <td>-0.723520</td>\n",
       "      <td>0.163591</td>\n",
       "      <td>0.686827</td>\n",
       "      <td>0.191903</td>\n",
       "      <td>0.072414</td>\n",
       "      <td>-0.018825</td>\n",
       "      <td>0.035194</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>226154</td>\n",
       "      <td>144514.0</td>\n",
       "      <td>-1.093171</td>\n",
       "      <td>1.836577</td>\n",
       "      <td>-0.964793</td>\n",
       "      <td>0.804425</td>\n",
       "      <td>0.495996</td>\n",
       "      <td>-0.419712</td>\n",
       "      <td>0.591444</td>\n",
       "      <td>0.741234</td>\n",
       "      <td>...</td>\n",
       "      <td>0.194233</td>\n",
       "      <td>0.654505</td>\n",
       "      <td>-0.258591</td>\n",
       "      <td>-0.450439</td>\n",
       "      <td>0.144125</td>\n",
       "      <td>-0.359537</td>\n",
       "      <td>0.299614</td>\n",
       "      <td>0.148007</td>\n",
       "      <td>13.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>118780</td>\n",
       "      <td>75211.0</td>\n",
       "      <td>1.276001</td>\n",
       "      <td>-0.656403</td>\n",
       "      <td>-0.732196</td>\n",
       "      <td>-0.564148</td>\n",
       "      <td>0.041672</td>\n",
       "      <td>0.204972</td>\n",
       "      <td>-0.112896</td>\n",
       "      <td>-0.088853</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.424230</td>\n",
       "      <td>-0.991840</td>\n",
       "      <td>-0.288935</td>\n",
       "      <td>-1.386478</td>\n",
       "      <td>0.594111</td>\n",
       "      <td>0.553389</td>\n",
       "      <td>-0.060694</td>\n",
       "      <td>-0.000594</td>\n",
       "      <td>109.32</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>279863</td>\n",
       "      <td>169142.0</td>\n",
       "      <td>-1.927883</td>\n",
       "      <td>1.125653</td>\n",
       "      <td>-4.518331</td>\n",
       "      <td>1.749293</td>\n",
       "      <td>-1.566487</td>\n",
       "      <td>-2.010494</td>\n",
       "      <td>-0.882850</td>\n",
       "      <td>0.697211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.778584</td>\n",
       "      <td>-0.319189</td>\n",
       "      <td>0.639419</td>\n",
       "      <td>-0.294885</td>\n",
       "      <td>0.537503</td>\n",
       "      <td>0.788395</td>\n",
       "      <td>0.292680</td>\n",
       "      <td>0.147968</td>\n",
       "      <td>390.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>280143</td>\n",
       "      <td>169347.0</td>\n",
       "      <td>1.378559</td>\n",
       "      <td>1.289381</td>\n",
       "      <td>-5.004247</td>\n",
       "      <td>1.411850</td>\n",
       "      <td>0.442581</td>\n",
       "      <td>-1.326536</td>\n",
       "      <td>-1.413170</td>\n",
       "      <td>0.248525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.370612</td>\n",
       "      <td>0.028234</td>\n",
       "      <td>-0.145640</td>\n",
       "      <td>-0.081049</td>\n",
       "      <td>0.521875</td>\n",
       "      <td>0.739467</td>\n",
       "      <td>0.389152</td>\n",
       "      <td>0.186637</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>280149</td>\n",
       "      <td>169351.0</td>\n",
       "      <td>-0.676143</td>\n",
       "      <td>1.126366</td>\n",
       "      <td>-2.213700</td>\n",
       "      <td>0.468308</td>\n",
       "      <td>-1.120541</td>\n",
       "      <td>-0.003346</td>\n",
       "      <td>-2.234739</td>\n",
       "      <td>1.210158</td>\n",
       "      <td>...</td>\n",
       "      <td>0.751826</td>\n",
       "      <td>0.834108</td>\n",
       "      <td>0.190944</td>\n",
       "      <td>0.032070</td>\n",
       "      <td>-0.739695</td>\n",
       "      <td>0.471111</td>\n",
       "      <td>0.385107</td>\n",
       "      <td>0.194361</td>\n",
       "      <td>77.89</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>982</th>\n",
       "      <td>281144</td>\n",
       "      <td>169966.0</td>\n",
       "      <td>-3.113832</td>\n",
       "      <td>0.585864</td>\n",
       "      <td>-5.399730</td>\n",
       "      <td>1.817092</td>\n",
       "      <td>-0.840618</td>\n",
       "      <td>-2.943548</td>\n",
       "      <td>-2.208002</td>\n",
       "      <td>1.058733</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583276</td>\n",
       "      <td>-0.269209</td>\n",
       "      <td>-0.456108</td>\n",
       "      <td>-0.183659</td>\n",
       "      <td>-0.328168</td>\n",
       "      <td>0.606116</td>\n",
       "      <td>0.884876</td>\n",
       "      <td>-0.253700</td>\n",
       "      <td>245.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>983</th>\n",
       "      <td>281674</td>\n",
       "      <td>170348.0</td>\n",
       "      <td>1.991976</td>\n",
       "      <td>0.158476</td>\n",
       "      <td>-2.583441</td>\n",
       "      <td>0.408670</td>\n",
       "      <td>1.151147</td>\n",
       "      <td>-0.096695</td>\n",
       "      <td>0.223050</td>\n",
       "      <td>-0.068384</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.164350</td>\n",
       "      <td>-0.295135</td>\n",
       "      <td>-0.072173</td>\n",
       "      <td>-0.450261</td>\n",
       "      <td>0.313267</td>\n",
       "      <td>-0.289617</td>\n",
       "      <td>0.002988</td>\n",
       "      <td>-0.015309</td>\n",
       "      <td>42.53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>984 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0      Time        V1        V2        V3        V4        V5  \\\n",
       "0        195843  131245.0  2.113416 -1.778946 -0.270242 -1.435794 -1.934593   \n",
       "1        175540  122383.0  1.807996  0.175712  0.078832  4.087285 -0.395966   \n",
       "2         49890   44253.0  1.235299  0.406386  0.455123  0.763918 -0.479694   \n",
       "3        226154  144514.0 -1.093171  1.836577 -0.964793  0.804425  0.495996   \n",
       "4        118780   75211.0  1.276001 -0.656403 -0.732196 -0.564148  0.041672   \n",
       "..          ...       ...       ...       ...       ...       ...       ...   \n",
       "979      279863  169142.0 -1.927883  1.125653 -4.518331  1.749293 -1.566487   \n",
       "980      280143  169347.0  1.378559  1.289381 -5.004247  1.411850  0.442581   \n",
       "981      280149  169351.0 -0.676143  1.126366 -2.213700  0.468308 -1.120541   \n",
       "982      281144  169966.0 -3.113832  0.585864 -5.399730  1.817092 -0.840618   \n",
       "983      281674  170348.0  1.991976  0.158476 -2.583441  0.408670  1.151147   \n",
       "\n",
       "           V6        V7        V8  ...       V21       V22       V23  \\\n",
       "0   -0.404340 -1.605464  0.028426  ...  0.130515  0.816912  0.124606   \n",
       "1    0.137835 -0.377114  0.219787  ...  0.152284  0.614129  0.158536   \n",
       "2   -1.246685  0.130762 -0.256403  ... -0.260211 -0.723520  0.163591   \n",
       "3   -0.419712  0.591444  0.741234  ...  0.194233  0.654505 -0.258591   \n",
       "4    0.204972 -0.112896 -0.088853  ... -0.424230 -0.991840 -0.288935   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "979 -2.010494 -0.882850  0.697211  ...  0.778584 -0.319189  0.639419   \n",
       "980 -1.326536 -1.413170  0.248525  ...  0.370612  0.028234 -0.145640   \n",
       "981 -0.003346 -2.234739  1.210158  ...  0.751826  0.834108  0.190944   \n",
       "982 -2.943548 -2.208002  1.058733  ...  0.583276 -0.269209 -0.456108   \n",
       "983 -0.096695  0.223050 -0.068384  ... -0.164350 -0.295135 -0.072173   \n",
       "\n",
       "          V24       V25       V26       V27       V28  Amount  Class  \n",
       "0    0.080239 -0.286359 -0.017499  0.030221 -0.043715   63.50      0  \n",
       "1    0.510383 -0.057457  0.085855 -0.016525 -0.055248    0.00      0  \n",
       "2    0.686827  0.191903  0.072414 -0.018825  0.035194    0.99      0  \n",
       "3   -0.450439  0.144125 -0.359537  0.299614  0.148007   13.99      0  \n",
       "4   -1.386478  0.594111  0.553389 -0.060694 -0.000594  109.32      0  \n",
       "..        ...       ...       ...       ...       ...     ...    ...  \n",
       "979 -0.294885  0.537503  0.788395  0.292680  0.147968  390.00      1  \n",
       "980 -0.081049  0.521875  0.739467  0.389152  0.186637    0.76      1  \n",
       "981  0.032070 -0.739695  0.471111  0.385107  0.194361   77.89      1  \n",
       "982 -0.183659 -0.328168  0.606116  0.884876 -0.253700  245.00      1  \n",
       "983 -0.450261  0.313267 -0.289617  0.002988 -0.015309   42.53      1  \n",
       "\n",
       "[984 rows x 32 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concat the X data and y data for prediction\n",
    "test_under_imb = pd.concat([x_rus, y_rus], axis=1)\n",
    "test_under_imb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X (984, 31)\n",
      "Shape of Y (984,)\n",
      "Accuracy of the model is  92.99\n"
     ]
    }
   ],
   "source": [
    "# Predicting the accuracy of the model for Random Undersampling using Imblearn library\n",
    "log_reg(test_under_imb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Random Over-Sampling by Imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 9000, 1: 492})\n",
      "Resample dataset shape Counter({1: 9000, 0: 9000})\n"
     ]
    }
   ],
   "source": [
    "# import library\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "# fit predictor and target variable\n",
    "x_ros, y_ros = ros.fit_resample(x, y)\n",
    "print('Original dataset shape', Counter(y))\n",
    "print('Resample dataset shape', Counter(y_ros))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>541</td>\n",
       "      <td>406.0</td>\n",
       "      <td>-2.312227</td>\n",
       "      <td>1.951992</td>\n",
       "      <td>-1.609851</td>\n",
       "      <td>3.997906</td>\n",
       "      <td>-0.522188</td>\n",
       "      <td>-1.426545</td>\n",
       "      <td>-2.537387</td>\n",
       "      <td>1.391657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.517232</td>\n",
       "      <td>-0.035049</td>\n",
       "      <td>-0.465211</td>\n",
       "      <td>0.320198</td>\n",
       "      <td>0.044519</td>\n",
       "      <td>0.177840</td>\n",
       "      <td>0.261145</td>\n",
       "      <td>-0.143276</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>623</td>\n",
       "      <td>472.0</td>\n",
       "      <td>-3.043541</td>\n",
       "      <td>-3.157307</td>\n",
       "      <td>1.088463</td>\n",
       "      <td>2.288644</td>\n",
       "      <td>1.359805</td>\n",
       "      <td>-1.064823</td>\n",
       "      <td>0.325574</td>\n",
       "      <td>-0.067794</td>\n",
       "      <td>...</td>\n",
       "      <td>0.661696</td>\n",
       "      <td>0.435477</td>\n",
       "      <td>1.375966</td>\n",
       "      <td>-0.293803</td>\n",
       "      <td>0.279798</td>\n",
       "      <td>-0.145362</td>\n",
       "      <td>-0.252773</td>\n",
       "      <td>0.035764</td>\n",
       "      <td>529.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4920</td>\n",
       "      <td>4462.0</td>\n",
       "      <td>-2.303350</td>\n",
       "      <td>1.759247</td>\n",
       "      <td>-0.359745</td>\n",
       "      <td>2.330243</td>\n",
       "      <td>-0.821628</td>\n",
       "      <td>-0.075788</td>\n",
       "      <td>0.562320</td>\n",
       "      <td>-0.399147</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.294166</td>\n",
       "      <td>-0.932391</td>\n",
       "      <td>0.172726</td>\n",
       "      <td>-0.087330</td>\n",
       "      <td>-0.156114</td>\n",
       "      <td>-0.542628</td>\n",
       "      <td>0.039566</td>\n",
       "      <td>-0.153029</td>\n",
       "      <td>239.93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6108</td>\n",
       "      <td>6986.0</td>\n",
       "      <td>-4.397974</td>\n",
       "      <td>1.358367</td>\n",
       "      <td>-2.592844</td>\n",
       "      <td>2.679787</td>\n",
       "      <td>-1.128131</td>\n",
       "      <td>-1.706536</td>\n",
       "      <td>-3.496197</td>\n",
       "      <td>-0.248778</td>\n",
       "      <td>...</td>\n",
       "      <td>0.573574</td>\n",
       "      <td>0.176968</td>\n",
       "      <td>-0.436207</td>\n",
       "      <td>-0.053502</td>\n",
       "      <td>0.252405</td>\n",
       "      <td>-0.657488</td>\n",
       "      <td>-0.827136</td>\n",
       "      <td>0.849573</td>\n",
       "      <td>59.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6329</td>\n",
       "      <td>7519.0</td>\n",
       "      <td>1.234235</td>\n",
       "      <td>3.019740</td>\n",
       "      <td>-4.304597</td>\n",
       "      <td>4.732795</td>\n",
       "      <td>3.624201</td>\n",
       "      <td>-1.357746</td>\n",
       "      <td>1.713445</td>\n",
       "      <td>-0.496358</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.379068</td>\n",
       "      <td>-0.704181</td>\n",
       "      <td>-0.656805</td>\n",
       "      <td>-1.632653</td>\n",
       "      <td>1.488901</td>\n",
       "      <td>0.566797</td>\n",
       "      <td>-0.010016</td>\n",
       "      <td>0.146793</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17995</th>\n",
       "      <td>150679</td>\n",
       "      <td>93879.0</td>\n",
       "      <td>-12.833631</td>\n",
       "      <td>7.508790</td>\n",
       "      <td>-20.491952</td>\n",
       "      <td>7.465780</td>\n",
       "      <td>-11.575304</td>\n",
       "      <td>-5.140999</td>\n",
       "      <td>-14.020564</td>\n",
       "      <td>8.332120</td>\n",
       "      <td>...</td>\n",
       "      <td>2.966842</td>\n",
       "      <td>0.615344</td>\n",
       "      <td>-0.766495</td>\n",
       "      <td>0.431261</td>\n",
       "      <td>-0.104975</td>\n",
       "      <td>-0.010091</td>\n",
       "      <td>-2.400811</td>\n",
       "      <td>-0.720557</td>\n",
       "      <td>104.03</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17996</th>\n",
       "      <td>8296</td>\n",
       "      <td>11080.0</td>\n",
       "      <td>-2.125490</td>\n",
       "      <td>5.973556</td>\n",
       "      <td>-11.034727</td>\n",
       "      <td>9.007147</td>\n",
       "      <td>-1.689451</td>\n",
       "      <td>-2.854415</td>\n",
       "      <td>-7.810441</td>\n",
       "      <td>2.030870</td>\n",
       "      <td>...</td>\n",
       "      <td>1.646518</td>\n",
       "      <td>-0.278485</td>\n",
       "      <td>-0.664841</td>\n",
       "      <td>-1.164555</td>\n",
       "      <td>1.701796</td>\n",
       "      <td>0.690806</td>\n",
       "      <td>2.119749</td>\n",
       "      <td>1.108933</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17997</th>\n",
       "      <td>108258</td>\n",
       "      <td>70828.0</td>\n",
       "      <td>0.196707</td>\n",
       "      <td>1.189757</td>\n",
       "      <td>0.704882</td>\n",
       "      <td>2.891388</td>\n",
       "      <td>0.045555</td>\n",
       "      <td>1.245730</td>\n",
       "      <td>-1.198714</td>\n",
       "      <td>-2.421616</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.328132</td>\n",
       "      <td>0.189311</td>\n",
       "      <td>-0.005524</td>\n",
       "      <td>-0.814708</td>\n",
       "      <td>0.400924</td>\n",
       "      <td>0.286281</td>\n",
       "      <td>0.135215</td>\n",
       "      <td>0.257315</td>\n",
       "      <td>0.76</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17998</th>\n",
       "      <td>6609</td>\n",
       "      <td>8090.0</td>\n",
       "      <td>-1.783229</td>\n",
       "      <td>3.402794</td>\n",
       "      <td>-3.822742</td>\n",
       "      <td>2.625368</td>\n",
       "      <td>-1.976415</td>\n",
       "      <td>-2.731689</td>\n",
       "      <td>-3.430559</td>\n",
       "      <td>1.413204</td>\n",
       "      <td>...</td>\n",
       "      <td>0.454032</td>\n",
       "      <td>-0.577526</td>\n",
       "      <td>0.045967</td>\n",
       "      <td>0.461700</td>\n",
       "      <td>0.044146</td>\n",
       "      <td>0.305704</td>\n",
       "      <td>0.530981</td>\n",
       "      <td>0.243746</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17999</th>\n",
       "      <td>191267</td>\n",
       "      <td>129186.0</td>\n",
       "      <td>0.290155</td>\n",
       "      <td>0.049243</td>\n",
       "      <td>-0.740524</td>\n",
       "      <td>2.865463</td>\n",
       "      <td>1.395294</td>\n",
       "      <td>-0.535163</td>\n",
       "      <td>0.142543</td>\n",
       "      <td>-0.222770</td>\n",
       "      <td>...</td>\n",
       "      <td>0.337349</td>\n",
       "      <td>1.018191</td>\n",
       "      <td>0.303550</td>\n",
       "      <td>0.833886</td>\n",
       "      <td>-1.222306</td>\n",
       "      <td>2.745261</td>\n",
       "      <td>-0.220402</td>\n",
       "      <td>0.168233</td>\n",
       "      <td>7.18</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18000 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0      Time         V1        V2         V3        V4  \\\n",
       "0             541     406.0  -2.312227  1.951992  -1.609851  3.997906   \n",
       "1             623     472.0  -3.043541 -3.157307   1.088463  2.288644   \n",
       "2            4920    4462.0  -2.303350  1.759247  -0.359745  2.330243   \n",
       "3            6108    6986.0  -4.397974  1.358367  -2.592844  2.679787   \n",
       "4            6329    7519.0   1.234235  3.019740  -4.304597  4.732795   \n",
       "...           ...       ...        ...       ...        ...       ...   \n",
       "17995      150679   93879.0 -12.833631  7.508790 -20.491952  7.465780   \n",
       "17996        8296   11080.0  -2.125490  5.973556 -11.034727  9.007147   \n",
       "17997      108258   70828.0   0.196707  1.189757   0.704882  2.891388   \n",
       "17998        6609    8090.0  -1.783229  3.402794  -3.822742  2.625368   \n",
       "17999      191267  129186.0   0.290155  0.049243  -0.740524  2.865463   \n",
       "\n",
       "              V5        V6         V7        V8  ...       V21       V22  \\\n",
       "0      -0.522188 -1.426545  -2.537387  1.391657  ...  0.517232 -0.035049   \n",
       "1       1.359805 -1.064823   0.325574 -0.067794  ...  0.661696  0.435477   \n",
       "2      -0.821628 -0.075788   0.562320 -0.399147  ... -0.294166 -0.932391   \n",
       "3      -1.128131 -1.706536  -3.496197 -0.248778  ...  0.573574  0.176968   \n",
       "4       3.624201 -1.357746   1.713445 -0.496358  ... -0.379068 -0.704181   \n",
       "...          ...       ...        ...       ...  ...       ...       ...   \n",
       "17995 -11.575304 -5.140999 -14.020564  8.332120  ...  2.966842  0.615344   \n",
       "17996  -1.689451 -2.854415  -7.810441  2.030870  ...  1.646518 -0.278485   \n",
       "17997   0.045555  1.245730  -1.198714 -2.421616  ... -1.328132  0.189311   \n",
       "17998  -1.976415 -2.731689  -3.430559  1.413204  ...  0.454032 -0.577526   \n",
       "17999   1.395294 -0.535163   0.142543 -0.222770  ...  0.337349  1.018191   \n",
       "\n",
       "            V23       V24       V25       V26       V27       V28  Amount  \\\n",
       "0     -0.465211  0.320198  0.044519  0.177840  0.261145 -0.143276    0.00   \n",
       "1      1.375966 -0.293803  0.279798 -0.145362 -0.252773  0.035764  529.00   \n",
       "2      0.172726 -0.087330 -0.156114 -0.542628  0.039566 -0.153029  239.93   \n",
       "3     -0.436207 -0.053502  0.252405 -0.657488 -0.827136  0.849573   59.00   \n",
       "4     -0.656805 -1.632653  1.488901  0.566797 -0.010016  0.146793    1.00   \n",
       "...         ...       ...       ...       ...       ...       ...     ...   \n",
       "17995 -0.766495  0.431261 -0.104975 -0.010091 -2.400811 -0.720557  104.03   \n",
       "17996 -0.664841 -1.164555  1.701796  0.690806  2.119749  1.108933    1.00   \n",
       "17997 -0.005524 -0.814708  0.400924  0.286281  0.135215  0.257315    0.76   \n",
       "17998  0.045967  0.461700  0.044146  0.305704  0.530981  0.243746    1.00   \n",
       "17999  0.303550  0.833886 -1.222306  2.745261 -0.220402  0.168233    7.18   \n",
       "\n",
       "       Class  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  \n",
       "...      ...  \n",
       "17995      1  \n",
       "17996      1  \n",
       "17997      1  \n",
       "17998      1  \n",
       "17999      1  \n",
       "\n",
       "[18000 rows x 32 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_over_imb = pd.concat([x_ros, y_ros], axis = 1)\n",
    "test_over_imb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X (18000, 31)\n",
      "Shape of Y (18000,)\n",
      "Accuracy of the model is  91.51\n"
     ]
    }
   ],
   "source": [
    "log_reg(test_over_imb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Under-sampling Tomek links\n",
    "\n",
    "It selects the classes that are close to each other and eliminates them. This helps to make sure that there some space between the classes and introduces variability between them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape: Counter({0: 9000, 1: 492})\n",
      "Resample dataset shape: Counter({0: 8829, 1: 492})\n"
     ]
    }
   ],
   "source": [
    "# load library\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "\n",
    "tom_link = TomekLinks(sampling_strategy='majority')\n",
    "\n",
    "# fit predictor and target variable\n",
    "x_tl, y_tl = tom_link.fit_resample(x, y)\n",
    "\n",
    "print('Original dataset shape:', Counter(y))\n",
    "print('Resample dataset shape:', Counter(y_tl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging the predictor and response variable\n",
    "test_under_tomek = pd.concat([x_tl,y_tl], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X (9321, 31)\n",
      "Shape of Y (9321,)\n",
      "Accuracy of the model is  98.65\n"
     ]
    }
   ],
   "source": [
    "log_reg(test_under_tomek)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "9487    0\n",
       "9488    0\n",
       "9489    0\n",
       "9490    0\n",
       "9491    0\n",
       "Name: Class, Length: 9492, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Synthetic Minority Oversampling Technique (SMOTE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training X labeled data        Unnamed: 0           Time         V1         V2         V3        V4  \\\n",
      "0             541     406.000000  -2.312227   1.951992  -1.609851  3.997906   \n",
      "1             623     472.000000  -3.043541  -3.157307   1.088463  2.288644   \n",
      "2            4920    4462.000000  -2.303350   1.759247  -0.359745  2.330243   \n",
      "3            6108    6986.000000  -4.397974   1.358367  -2.592844  2.679787   \n",
      "4            6329    7519.000000   1.234235   3.019740  -4.304597  4.732795   \n",
      "...           ...            ...        ...        ...        ...       ...   \n",
      "17995       64315   51093.783406 -10.328863   7.565426 -13.288927  4.292912   \n",
      "17996      151023   94405.539661 -21.794928  13.770434 -25.262273  8.057102   \n",
      "17997        6403    7589.211567   0.548148   2.755503  -5.555362  4.667975   \n",
      "17998      273420  165544.616207  -4.488726   0.892980  -3.527128  2.248782   \n",
      "17999      203487  134837.244514  -0.035220   2.587341  -5.560888  6.173897   \n",
      "\n",
      "              V5        V6         V7        V8  ...       V20       V21  \\\n",
      "0      -0.522188 -1.426545  -2.537387  1.391657  ...  0.126911  0.517232   \n",
      "1       1.359805 -1.064823   0.325574 -0.067794  ...  2.102339  0.661696   \n",
      "2      -0.821628 -0.075788   0.562320 -0.399147  ... -0.430022 -0.294166   \n",
      "3      -1.128131 -1.706536  -3.496197 -0.248778  ... -0.171608  0.573574   \n",
      "4       3.624201 -1.357746   1.713445 -0.496358  ...  0.009061 -0.379068   \n",
      "...          ...       ...        ...       ...  ...       ...       ...   \n",
      "17995  -7.940114 -3.443376  -8.538499  7.162234  ...  0.843975  0.935574   \n",
      "17996 -14.741843 -0.542100 -26.155672 -9.429465  ...  2.285750 -7.304393   \n",
      "17997  -1.112025 -2.133327  -3.390264  0.838739  ...  0.500620  0.533947   \n",
      "17998   1.565938 -0.157326  -3.685296 -8.188515  ... -0.168426 -3.228960   \n",
      "17999  -1.725689  0.210525   0.205917 -1.364650  ...  0.799954 -0.439119   \n",
      "\n",
      "            V22       V23       V24       V25       V26       V27       V28  \\\n",
      "0     -0.035049 -0.465211  0.320198  0.044519  0.177840  0.261145 -0.143276   \n",
      "1      0.435477  1.375966 -0.293803  0.279798 -0.145362 -0.252773  0.035764   \n",
      "2     -0.932391  0.172726 -0.087330 -0.156114 -0.542628  0.039566 -0.153029   \n",
      "3      0.176968 -0.436207 -0.053502  0.252405 -0.657488 -0.827136  0.849573   \n",
      "4     -0.704181 -0.656805 -1.632653  1.488901  0.566797 -0.010016  0.146793   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "17995 -0.910444 -0.192804 -0.034162  0.583678 -0.262918  1.114770  0.220009   \n",
      "17996  2.978706  0.763217  0.045780 -0.629510 -0.776799 -6.059731 -1.116946   \n",
      "17997 -0.068051  0.318775 -0.242534 -1.018579  0.390530  0.629512  0.201879   \n",
      "17998  1.545126  0.957617 -0.041958 -0.197698  0.428544  0.999365  0.256764   \n",
      "17999  0.091715  0.736792 -0.020663 -0.844011  0.080064  0.757211  0.239207   \n",
      "\n",
      "           Amount  \n",
      "0        0.000000  \n",
      "1      529.000000  \n",
      "2      239.930000  \n",
      "3       59.000000  \n",
      "4        1.000000  \n",
      "...           ...  \n",
      "17995   99.990000  \n",
      "17996    6.423419  \n",
      "17997    1.000000  \n",
      "17998   25.015448  \n",
      "17999  528.156974  \n",
      "\n",
      "[18000 rows x 31 columns]\n",
      "Testing_y_Smote 0        1\n",
      "1        1\n",
      "2        1\n",
      "3        1\n",
      "4        1\n",
      "        ..\n",
      "17995    1\n",
      "17996    1\n",
      "17997    1\n",
      "17998    1\n",
      "17999    1\n",
      "Name: Class, Length: 18000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE as sm\n",
    "\n",
    "smot = sm(random_state=42)\n",
    "X_train_smote, y_train_smote = smot.fit_resample(x,y)\n",
    "\n",
    "\n",
    "print(\"Training X labeled data\", X_train_smote)\n",
    "print(\"Testing_y_Smote\", y_train_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging the dataset\n",
    "test_Over_smote = pd.concat([X_train_smote, y_train_smote], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X (18000, 31)\n",
      "Shape of Y (18000,)\n",
      "Accuracy of the model is  95.7\n"
     ]
    }
   ],
   "source": [
    "# Predicting the value of the Fraud cases using log regression\n",
    "\n",
    "log_reg(test_Over_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we got an accuracy of 95.7%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Near Miss Algorithm\n",
    "In undersampling techniques, there are times when we have to deal with information loss.\n",
    "\n",
    "In this algorithm, if two class variables are very close to each other, the nwe remove the Majorty class variable in order to improve the spacing between the Class variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:      Unnamed: 0      Time        V1        V2        V3        V4        V5  \\\n",
      "0        251875  155540.0  2.021473  0.201487 -1.578119  0.333436  0.488698   \n",
      "1         10490   17208.0  1.258132  0.363787  0.655607  0.825867 -0.397760   \n",
      "2         10495   17216.0  1.236245 -0.308689 -0.479570 -0.095878  1.651517   \n",
      "3        123286   76870.0 -1.050697  1.500753  0.846326 -0.282956  0.059866   \n",
      "4        251856  155530.0  0.163969  1.045849 -1.211776 -0.202435  0.509677   \n",
      "..          ...       ...       ...       ...       ...       ...       ...   \n",
      "979      279863  169142.0 -1.927883  1.125653 -4.518331  1.749293 -1.566487   \n",
      "980      280143  169347.0  1.378559  1.289381 -5.004247  1.411850  0.442581   \n",
      "981      280149  169351.0 -0.676143  1.126366 -2.213700  0.468308 -1.120541   \n",
      "982      281144  169966.0 -3.113832  0.585864 -5.399730  1.817092 -0.840618   \n",
      "983      281674  170348.0  1.991976  0.158476 -2.583441  0.408670  1.151147   \n",
      "\n",
      "           V6        V7        V8  ...       V20       V21       V22  \\\n",
      "0   -0.635697  0.165885 -0.168598  ... -0.076761 -0.287503 -0.700131   \n",
      "1   -0.942710 -0.018338 -0.294385  ... -0.122712 -0.404720 -0.921133   \n",
      "2    3.895960 -1.130139  0.919560  ... -0.002983 -0.136586 -0.095002   \n",
      "3   -0.561182  0.484517  0.181547  ...  0.457988 -0.335560 -0.780232   \n",
      "4   -0.832113  0.450792  0.331968  ... -0.244562  0.351071  0.947610   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "979 -2.010494 -0.882850  0.697211  ...  1.252967  0.778584 -0.319189   \n",
      "980 -1.326536 -1.413170  0.248525  ...  0.226138  0.370612  0.028234   \n",
      "981 -0.003346 -2.234739  1.210158  ...  0.247968  0.751826  0.834108   \n",
      "982 -2.943548 -2.208002  1.058733  ...  0.306271  0.583276 -0.269209   \n",
      "983 -0.096695  0.223050 -0.068384  ... -0.017652 -0.164350 -0.295135   \n",
      "\n",
      "          V23       V24       V25       V26       V27       V28  Amount  \n",
      "0    0.337059  0.702214 -0.272784  0.138696 -0.058354 -0.036335    0.89  \n",
      "1    0.144462  0.322978  0.197592  0.055193 -0.055443  0.013369    4.49  \n",
      "2   -0.137830  1.011304  0.623230  0.485574 -0.022022  0.007777   19.95  \n",
      "3   -0.027029 -0.090180 -0.022896  0.091830  0.547241  0.278780    1.29  \n",
      "4   -0.125083 -0.560980 -0.277630 -0.137798 -0.074601 -0.059932   16.79  \n",
      "..        ...       ...       ...       ...       ...       ...     ...  \n",
      "979  0.639419 -0.294885  0.537503  0.788395  0.292680  0.147968  390.00  \n",
      "980 -0.145640 -0.081049  0.521875  0.739467  0.389152  0.186637    0.76  \n",
      "981  0.190944  0.032070 -0.739695  0.471111  0.385107  0.194361   77.89  \n",
      "982 -0.456108 -0.183659 -0.328168  0.606116  0.884876 -0.253700  245.00  \n",
      "983 -0.072173 -0.450261  0.313267 -0.289617  0.002988 -0.015309   42.53  \n",
      "\n",
      "[984 rows x 31 columns]\n",
      "Testing Data: 0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "979    1\n",
      "980    1\n",
      "981    1\n",
      "982    1\n",
      "983    1\n",
      "Name: Class, Length: 984, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "near_miss = NearMiss()\n",
    "\n",
    "x_train_nm, y_test_nm = near_miss.fit_resample(x,y)\n",
    "print(\"Training Data:\",x_train_nm)\n",
    "print(\"Testing Data:\", y_test_nm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging both the data\n",
    "test_under_never_miss = pd.concat([x_train_nm, y_test_nm], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X (984, 31)\n",
      "Shape of Y (984,)\n",
      "Accuracy of the model is  92.78\n"
     ]
    }
   ],
   "source": [
    "# Predicting the value of the Fraud cases using log regression\n",
    "\n",
    "log_reg(test_under_never_miss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Change the Performance Metrics\n",
    "\n",
    "Accuracy is not the best metric to use when evaluating imbalanced datasets as it can be misleading.\n",
    "Metrics that can provide better insight are:<br>\n",
    "\n",
    "1. Confusion Matrix: a table showing correct predictions and types of incorrect predictions.\n",
    "2. Precision: the number of true positives divided by all positive predictions. Precision is also called Positive Predictive Value. It is a measure of a classifier’s exactness. Low precision indicates a high number of false positives.\n",
    "3. Recall: the number of true positives divided by the number of positive values in the test data. The recall is also called Sensitivity or the True Positive Rate. It is a measure of a classifier’s completeness. Low recall indicates a high number of false negatives.\n",
    "4. F1: Score: the weighted average of precision and recall.\n",
    "5. Area Under ROC Curve (AUROC): AUROC represents the likelihood of your model distinguishing observations from two classes.\n",
    "In other words, if you randomly select one observation from each class, what’s the probability that your model will be able to “rank” them correctly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7c502e12f5fe822f5adec0fbbf0adb265abfc64a47338c1c93e2daf7c2ae52c2"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
